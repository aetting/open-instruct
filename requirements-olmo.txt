# TODO When updating flash-attn or torch in the future, make sure to update the version in the Dockerfile 
torch<=2.3.0
scipy
packaging
sentencepiece
datasets
accelerate==0.31.0
peft>=0.11.1
bitsandbytes>=0.41.1
evaluate>=0.4.0
tokenizers==0.19.1
protobuf
transformers>=4.40
openai>=1.0.0
tiktoken
rouge_score
tensorboard
wandb
gradio>=3.50.2
termcolor
jsonlines
unidic-lite
einops
flash-attn==2.5.8 # should really only be in dockerfile. Local env often doesn't have GPUs
fire
alpaca-eval==0.6.2
# for human eval web app
flask
vllm>=0.4.2  # for compatibility with olmo
openpyxl
# for ifeval
nltk
langdetect
immutabledict
# for linting
black
flake8
isort